# System Architecture

## 1. Overview

This document outlines the architecture of the Second Brain backend system. The system is designed to function as a personal knowledge base, capable of capturing, processing, and intelligently retrieving user information through a conversational interface. It ingests unstructured data from chats, extracts structured knowledge, builds a knowledge graph, and proactively provides insights to the user.

## 2. Core Concepts

-   **Memory**: The fundamental unit of information. A memory can be a note, fact, event, or any other type defined in `src/models/memory.ts`. Each memory contains content, a type, timestamps, and metadata such as `importance` and a `confidenceScore`.
-   **Entity**: A named concept, such as a person, place, project, or topic (e.g., "Sarah", "Project Titan"). Entities are extracted from memories and chat messages to build a structured understanding of the user's world.
-   **EntityLink (Triplet)**: A directed relationship between entities, forming a knowledge triplet (Subject-Predicate-Object). For example: `(Sarah, is lead of, AI Team)`. These links constitute the knowledge graph.
-   **Embedding**: A vector representation of a memory's content. Embeddings are used for semantic similarity searches, allowing the system to find conceptually related memories even if they don't share keywords.
-   **Proactive Alert**: An insight generated by the system without a direct user query. The system analyzes the knowledge base to find reminders, detect patterns, suggest connections, and identify knowledge gaps.

## 3. System Components

The backend is composed of four main components:

-   **Web Server (`src/app.ts`)**: An Express.js application that exposes the REST API for synchronous user interactions. It also uses `node-cron` to schedule and execute all periodic background jobs.
-   **Background Worker (`src/worker.ts`)**: A dedicated process that listens for and processes asynchronous, long-running jobs from the message queue. This offloads computationally expensive tasks like LLM-based information extraction from the main request-response cycle.
-   **Database (PostgreSQL + `pg_vector`)**: The primary data store, managed with the Prisma ORM. It houses all user data, including memories, entities, and their vector embeddings. The `pg_vector` extension enables efficient vector similarity searches.
-   **Message Queue (Redis + BullMQ)**: Manages and persists background jobs. When a task is too slow for a synchronous web request (e.g., extracting memories from a conversation), it is added to the `memoryQueue` to be processed by the `memoryWorker`.

## 4. Data Model (`prisma/schema.prisma`)

The database schema is the backbone of the system:

-   **User**: Represents a system user.
-   **Chat**: A conversation session between a user and the assistant.
-   **ChatMessage**: A single message within a chat, belonging to either the user or the assistant.
-   **Memory**: The core data model. It stores content, type, and metadata like `importance` and `confidenceScore` (which facilitates a "forgetting" mechanism).
-   **Embedding**: Stores the vector embedding for a memory, linked one-to-one.
-   **Entity**: A unique named entity belonging to a user.
-   **EntityLink**: A directed edge in the knowledge graph. It links a subject `Entity` to an object `Entity` (or a `Memory`/`ChatMessage`) with a specific `role` (predicate), forming a knowledge triplet.
-   **Summary**: Stores AI-generated summaries of memories (e.g., daily summaries).

## 5. API Endpoints

The system exposes RESTful endpoints for interaction:

#### `/api/chat`

-   `POST /`: Creates a new chat session.
-   `GET /proactive`: Fetches proactive alerts for the user.
-   `GET /:chatId`: Retrieves the message history for a specific chat.
-   `POST /ingest` (Legacy): Directly ingests a new memory.
-   `POST /query` (Legacy): Directly queries memories.

#### `/api/memories`

-   `GET /all`: Retrieves all memories for a user.
-   `POST /:memoryId/reinforce`: Increases the importance score of a memory.
-   `DELETE /:memoryId`: Soft-deletes a memory.

#### `/api/graph`

-   `GET /entities`: Retrieves entities, with an option to filter by type.
-   `GET /relationships/:entityName`: Retrieves all relationships for a given entity.

## 6. Service Layer (`src/services`)

This layer contains the core business logic of the application.

-   **`chat.service.ts`**: Orchestrates the entire chat flow, from retrieving context to generating a response and queueing post-processing tasks.
-   **`llm.service.ts`**: A wrapper for the Ollama API, providing methods for text generation, streaming, and creating embeddings.
-   **`memory.service.ts`**: Manages CRUD operations for memories and orchestrates the retrieval process.
-   **`memory-index.service.ts`**: Implements "smart search" via a hybrid approach, combining vector similarity and full-text search. It uses a sophisticated scoring function that weighs recency, access frequency, importance, and confidence to rank results.
-   **`memory-extractor.service.ts`**: Executed by the background worker, this service uses an LLM to parse conversations and extract salient memories for permanent storage.
-   **`memory-association.service.ts`**: Computes and stores associations between memories based on vector similarity, creating "constellations" of related information.
-   **`memory-deduplication.service.ts`**: Cleans the knowledge base by finding and merging duplicate memories.
-   **`graph.service.ts`**: Provides an interface for querying the knowledge graph (entities and their relationships).
-   **`reasoning.service.ts`**: Performs high-level cognitive tasks, such as detecting implications between memories, identifying knowledge gaps, building timelines, and performing multi-hop graph reasoning.
-   **`proactive.service.ts`**: Generates proactive alerts by analyzing memories for reminders, connection opportunities, behavioral patterns, and knowledge gaps.
-   **`contradiction-detection.service.ts`**: Scans for contradictions between new and existing information and provides resolution strategies.

## 7. Background Jobs (`src/jobs`)

These are periodic tasks scheduled in `app.ts` via `node-cron` that maintain and enrich the knowledge base.

-   **`archiving.job.ts`**: Archives old, unimportant memories.
-   **`confidence-decay.job.ts`**: Implements a "forgetting" mechanism by reducing the `confidenceScore` of memories that are not accessed over time.
-   **`summarization.job.ts`**: Generates daily summaries of new memories using an LLM.
-   **`triplet_extraction.job.ts`**: The primary knowledge extraction process. It scans new content, uses an LLM to extract Subject-Predicate-Object triplets, and populates the `Entity` and `EntityLink` tables to grow the knowledge graph.

## 8. Request Flow Examples

### Flow 1: User Sends a Chat Message

1.  A `POST` request hits the chat endpoint, which calls `chatService.streamChatResponse`.
2.  The `chatService` saves the user's message.
3.  It calls `memoryIndexService.searchMemories` to retrieve relevant memories using a hybrid search algorithm with smart scoring.
4.  It then calls the `reasoningService` to find deeper implications and connections within the retrieved context.
5.  A detailed prompt is constructed, containing the chat history, relevant memories, and reasoning insights.
6.  `llmService.generateCompletionStream` is called, and the response is streamed back to the user.
7.  Upon completion, the full assistant response is saved, and a job is added to the `memoryQueue`.
8.  The `memoryWorker` picks up the job and invokes `memoryExtractorService` to parse the conversation and persist new, salient memories.

### Flow 2: Proactive Alert Generation

1.  A `node-cron` job in `app.ts` runs hourly, triggering `proactiveService.generateProactiveAlerts`.
2.  The `proactiveService` executes several analytical checks:
    -   **Reminders**: Queries for memories with upcoming `recordedAt` dates.
    -   **Connections**: Analyzes recent chats for mentioned people and finds unresolved, historical memories related to them.
    -   **Patterns**: Identifies recurring keywords (e.g., "stressed") in recent memories and suggests past solutions.
    -   **Gaps**: Calls the `reasoningService` to find entities that are frequently mentioned but lack a definition.
3.  The generated alerts are compiled, sorted by priority, and made available to the user via the `GET /api/chat/proactive` endpoint.